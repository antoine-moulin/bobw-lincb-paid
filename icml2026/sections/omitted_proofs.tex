\section{Temp Antoine: Regret analysis}

    \subsection{Notation}

\antoine{Writing new notation here, propagate back into the main text later} For $\alpha \in \spr*{0, 1}$, we define the negative Tsallis entropy with parameter $\alpha$ over the nonnegative orthant $\bbRnnK$ as
%
\begin{equation*}
    H_\alpha \spr*{q} = \frac{1}{1 - \alpha} \sumaK \spr*{q_a - q_a^\alpha}.
\end{equation*}
%
\db{Mettre $1/\alpha$}
Note that $\nabla H_\alpha \spr*{q} = \frac{1}{1 - \alpha} \spr*{\bfone - \alpha q^{\alpha - 1}}$, and $\nabla^2 H_\alpha \spr*{x} = \alpha \Diag \spr*{q^{\alpha - 2}}$. At time $t$, for any context $x$ and arm $a$, the losses are defined as $\ell_t \spr*{x, a} = \inp*{x, \theta_{t, a}}$. We denote $p_t \spr*{x}$ the probability of observing each arm at time $t$ for context $x$, \ie, $p_t \spr*{x} = \bbP_t \sbr*{a \in O_t \given X_t = x}$, and we let $\Sigma_t = \bbE_t \sbr*{p_t \spr*{X_t} X_t X_t\transpose}$ the (conditional) covariance matrix of the contexts for the observed actions. We denote $\ptmin = \min_{x \in \cX} p_t \spr*{x}$. We consider the corresponding importance-weighted estimator $\wh{\theta}_{t, a} = \Sigma_t^{-1} X_t \ell_t \spr*{X_t, a} \, \ind_{\scbr*{a \in O_t}}$ and note that this is an unbiased estimator
%
\begin{align*}
    \bbE_t \sbr*{\wh{\theta}_{t, a}} &= \Sigma_t^{-1} \bbE_t \sbr*{X_t X_t\transpose \theta_{t, a} \ind_{\scbr*{a \in O_t}}}\\
    &= \Sigma_t^{-1} \bbE_t \sbr*{X_t X_t\transpose \theta_{t, a} \bbE_t \sbr*{\ind_{\scbr*{a \in O_t}} \given X_t}}\\
    &= \Sigma_t^{-1} \bbE_t \sbr*{p_t \spr*{X_t} X_t X_t\transpose} \theta_{t, a}\\
    &= \theta_{t, a},
\end{align*}
%
where we used the definition of the losses $\ell_t$, the law of total expectation, and the definitions of $p_t$ and $\Sigma_t$. We further denote $\wt{\theta}_{t, a}$ the MGR approximation of $\wh{\theta}_{t, a}$, defined as
%
\begin{equation*}
    \wt{\theta}_{t, a} = \whsigmaplust X_t \ell_t \spr*{X_t, a} \, \ind_{\scbr*{a \in O_t}},
\end{equation*}
%
where $\whsigmaplust$ is the random matrix output by the MGR procedure in Algorithm~\ref{alg:MGR}. This is a biased estimator, and assuming the procedure sampled $M_t$ additional contexts, we have \antoine{check the last equation carefully}
%
\begin{align*}
    \bbE_t \sbr*{\wt{\theta}_{t, a}} &= \bbE_t \sbr*{\whsigmaplust} \bbE_t \sbr*{X_t \ell_t \spr*{X_t, a} \, \ind_{\scbr*{a \in O_t}}}\\
    &= \bbE_t \sbr*{\whsigmaplust} \Sigma_t \cdot \theta_{t, a}\\
    &= \theta_{t, a} - \spr*{I - \frac12 \Sigma_t}^{M_t} \theta_{t, a}.
\end{align*}
%
We denote $\wh{\ell}_t$ and $\wt{\ell}_t$ the corresponding losses. For any $x$, any $t$, we consider the policies $q_t$ defined as
%
\begin{equation*}
    q_t \spr*{\cdot \given x} = \argmin_{q \in \Delta_K} \scbr*{\sum_{s=1}^{t-1} \inp*{q, \wt \ell_s \spr*{x}} + \psi_t \spr*{q} + \bar\psi \spr*{q}},
\end{equation*}
%
where we defined $\psi_t \spr*{q} = \frac{1}{\eta_t} H_\alpha \spr*{q}$ for some $\eta_t > 0$ to be defined, $\bar\psi \spr*{q} = \bar\beta H_{\bar\alpha} \spr*{q}$ with $\bar\alpha = 1 - \alpha$ and some $\bar\beta > 0$ to be defined, and $\wt \ell_s \spr*{x} \in \bbR^K$ is the vector of estimated losses at time $s$ for context $x$, with components $\wt \ell_s \spr*{x, a} = \inp*{x, \wt \theta_{s, a}}$ for any $a \in \sbr*{K}$.



    \subsection{Analysis}

Recall the definition of the regret
%
\begin{align*}
    R_T &= \bbE \sbr*{\sumtT \spr*{\ell_t \spr*{X_t, A_t} - \ell_t \spr*{X_t, \pi_T^\star \spr*{X_t}}}} + c\,\bbE \sbr*{\sumtT \abs*{O_t}}\\
    &= \bbE \sbr*{\sumtT \sumaK \spr*{q_t \spr*{a \given X_t} - \pi_T^\star \spr*{a \given X_t}} \inp*{X_t, \theta_{t, a}}} + c K\,\bbE \sbr*{\sumtT p_t \spr*{X_t}},
\end{align*}
%
where we used the fact that $\bbE_t \sbr*{\ell_t \spr*{X_t, a}} = \inp*{X_t, \theta_{t, a}}$ for any $a \in \sbr*{K}$ for the first term, and that $\bbE_t \sbr*{\abs*{O_t} \given X_t} = K p_t \spr*{X_t}$ for the second term, which holds because at time $t$, each arm $a$ is observed with probability $p_t \spr*{X_t}$.

We introduce a ghost sample $X_0 \sim \cD$ independent from $\cH_T$. Conditional on $\cH_{t-1}$, both $X_t$ and $X_0$ are \iid from $\cD$, and $p_t$ is $\cH_{t-1}$-measurable, hence, we have
%
\begin{equation*}
    \bbE_t \sbr*{p_t \spr*{X_t}} = \bbE_t \sbr*{p_t \spr*{X_0}}.
\end{equation*}
%
By Lemma~\ref{lem:ghost-sample-neu} and the fact that $\wh{\theta}_{t, a}$ is an unbiased estimator of $\theta_{t, a}$, \ie $\bbE_t \sbr{\wh{\theta}_{t, a}} = \theta_{t, a}$, we can further rewrite the regret as \antoine{there is a bug with the upper bound on the bias term at the end}
%
\begin{align*}
    R_T &= \bbE \sbr*{\sumtT \sumaK \spr*{q_t \spr*{a \given X_0} - \pi_T^\star \spr*{a \given X_0}} \inp*{X_0, \wh{\theta}_{t, a}}} + c K\,\bbE \sbr*{\sumtT p_t \spr*{X_0}}\\
    &= \bbE \sbr*{\sumtT \sumaK \spr*{q_t \spr*{a \given X_0} - \pi_T^\star \spr*{a \given X_0}} \inp*{X_0, \wt{\theta}_{t, a}}} + c K\,\bbE \sbr*{\sumtT p_t \spr*{X_0}}\\
    &\quad+ \bbE \sbr*{\sumtT \sumaK \spr*{q_t \spr*{a \given X_0} - \pi_T^\star \spr*{a \given X_0}} \inp*{X_0, \wh{\theta}_{t, a} - \wt{\theta}_{t, a}}}\\
    &\leq \bbE \sbr*{\sumtT \sumaK \spr*{q_t \spr*{a \given X_0} - \pi_T^\star \spr*{a \given X_0}} \inp*{X_0, \wt{\theta}_{t, a}}} + c K\,\bbE \sbr*{\sumtT p_t \spr*{X_0}}\\
    &\quad+ 2 \sumtT \max_{a \in \sbr*{K}} \abs*{\bbE \sbr*{\inp*{X_0, \wh{\theta}_{t, a} - \wt{\theta}_{t, a}}}}.
\end{align*}
%
For any context $x \in \cX$, we define the auxiliary regret
%
\begin{equation*}
    \wt R_T \spr*{x} \coloneqq \sumtT \sumaK \spr*{q_t \spr*{a \given x} - \pi_T^\star \spr*{a \given x}} \inp*{x, \wt{\theta}_{t, a}} + c K \sumtT p_t \spr*{x}
\end{equation*}
%
and the bias induced by MGR
%
\begin{equation*}
    \biasmgr \coloneqq \sumtT \max_{a \in \sbr*{K}} \abs*{\bbE \sbr*{\inp*{X_0, \wh{\theta}_{t, a} - \wt{\theta}_{t, a}}}}.
\end{equation*}
%
With this notation, we can write the inequality above as
%
\begin{equation*}
    R_T \leq \bbE_{X_0 \sim \cD} \sbr*{\wt R_T \spr*{X_0}} + 2\,\biasmgr.
\end{equation*}
%
We bound the two terms separately. In Lemma~\ref{lem::boundBias} we prove that the bias induced by MGR is upper bounded as
%
\begin{equation*}
    2 \biasmgr \leq \frac{\pi^2}{3}\,.
\end{equation*}
%
Thus, it remains to upper bound $\bbE_{X_0 \sim \cD} \sbr*{\wt R_T \spr*{X_0}}$. Let us fix a context $x \in \cX$ and recall that at time $t$, the distribution $q_t \spr*{\cdot \given x}$ is
%
\begin{equation*}
    q_t \spr*{\cdot \given x} = \argmin_{q \in \Delta_K} \scbr*{\sum_{s=1}^{t-1} \sumaK q \spr*{a} \inp*{x, \wt{\theta}_{s, a}} + \cR_t \spr*{q}},
\end{equation*}
%
where we denoted $\cR_t \spr*{q} = \frac{1}{\eta_t} H_\alpha \spr*{q} + \bar\beta H_{\bar\alpha} \spr*{q}$. By the standard FTRL analysis \citep[Exercise~28.12]{BanditBook} \antoine{copy/prove the lemma in Technical tools appendix and refer to it}, we have
%
\db{I guess for later we should write everything with expectations here? or bound $\bE[\stabt]$ below.}
\begin{align*}
    \wt R_T \spr*{x} &\leq \sumtT \underbrace{\spr*{\sumaK \spr*{q_t \spr*{a \given x} - q_{t+1} \spr*{a \given x}} \inp{x, \wt \theta_{t, a}} - D_{\cR_t} \spr*{q_{t+1} \spr*{\cdot \given x}, q_t \spr*{\cdot \given x}}}}_{= \stabt}\\
    &\quad+ \underbrace{\cR_{T+1} \spr*{\pi_T^\star \spr*{\cdot \given x}} - \cR_1 \spr*{q_1 \spr*{\cdot \given x}} + \sumtT \spr*{\frac{1}{\eta_{t+1}} - \frac{1}{\eta_t}} H_{\alpha} \spr*{q_{t+1} \spr*{\cdot \given x}}}_{= \pen}\\
    &\quad+ c K \sumtT p_t \spr*{x},
\end{align*}
%
where the Bregman divergence of the composite regularizer is given by
%
\begin{equation*}
    D_{\cR_t} \spr*{q, q'} = \cR_t \spr*{q} - \cR_t \spr*{q'} - \inp*{\nabla \cR_t \spr*{q'}, q - q'} = \frac{1}{\eta_t} D_{H_\alpha} \spr*{q, q'} + \bar\beta D_{H_{\bar\alpha}} \spr*{q, q'},
\end{equation*}
%
and the Bregman divergence associated to $H_\alpha$ is
%
\begin{align*}
    D_{H_\alpha} \spr*{q, q'} &= H_\alpha \spr*{q} - H_\alpha \spr*{q'} - \inp*{\nabla H_\alpha \spr*{q'}, q - q'}\\
    &= \frac{1}{\alpha} \sumaK \spr*{q_a - q_a' - q_a^\alpha + \spr*{q_a'}^\alpha + \spr*{\alpha \spr*{q_a'}^{\alpha - 1} - 1} \spr*{q_a - q_a'}}\\
    &= \frac{1}{\alpha} \sumaK \spr*{\spr*{q_a'}^\alpha - q_a^\alpha + \alpha \spr*{q_a'}^{\alpha - 1} \spr*{q_a - q_a'}}.
\end{align*}
\db{use the right entropy}

\paragraph{Controlling the stability term.} Denote $\stab = \sumtT \stabt$. Noting that $D_{H_{\bar\alpha}}$ is non-negative, we have
%
\begin{align*}
    \stabt &\leq \sumaK \spr*{q_t \spr*{a \given x} - q_{t+1} \spr*{a \given x}} \inp{x, \wt \theta_{t, a}} - \frac{1}{\eta_t} D_{H_\alpha} \spr*{q_{t+1} \spr*{\cdot \given x}, q_t \spr*{\cdot \given x}}\\
    &= \frac{1}{\eta_t} \spr*{\sumaK \spr*{q_t \spr*{a \given x} - q_{t+1} \spr*{a \given x}} \eta_t \inp{x, \wt \theta_{t, a}} - D_{H_\alpha} \spr*{q_{t+1} \spr*{\cdot \given x}, q_t \spr*{\cdot \given x}}}.
\end{align*}
%
We need to control the magnitude of $\eta_t \inp{x, \wt \theta_{t, a}}$. Using the definition of $\wt \theta_{t, a}$ and the fact that $\norm{x}_2 \leq 1$, we have \antoine{seems to be the first constraint on the choice of $\eta_t$, we need to set it so we can use Lemma~\ref{lem::ub_ftrl_technical}}
\db{Not on the choice of $\eta_t$ but on the choice of $u_t$. }
To be able to use Lemma~\ref{lem::ub_ftrl_technical}, we need to choose $u_t$ in order to verify that 
%
\begin{equation}\label{eq::as_bound}
    \abs{\eta_t \inp{x, \wt \theta_{t, a}}} \leq \frac{1 - \alpha}{4} \cdot \frac{1}{q_{t\star}(x)^{1 - \alpha}}
\end{equation}
For the moment, forget about MGR and assume that the estimate is of the form $\wt \theta_{t,a} = \Sigma_t^{-1}X_t\ell_t(X_t, a)\ind(a\in O_t)$, where $\Sigma_t$ is any matrix that makes the estimator unbiased/with controlled bias. Then, following e.g the proof of Lemma 2 of \cite{BOBWlinear} we can write that 
\begin{align*}
	\abs{\inp{x, \wt \theta_{t,a}}} &\leq \norm{\Sigma_t^{-1}}_{\text{op}} \\
	& \leq  \frac{1}{\lambda_{\min}(\Sigma_t)} \;, \\
\end{align*}
using that all contexts are in the unit Euclidean ball. Some examples are
\begin{itemize}
	\item[(i)]  $\Sigma_t=p_t(X_t) \Sigma$, which yields $\lambda_{\min}(\Sigma_t) = p_t(X_t)\cdot \lambda_{\min}(\Sigma)$.
	\item[(ii)] $\Sigma_t=\E_{t, X\sim \cD}\left[p_t(X) XX^T\right]$, which gives $\Sigma_t\succeq \lambda_{\min}(\Sigma)\; \underset{x\in \cX}{ \min } \;p_t(x)\cdot  I$ so $\lambda_{\min}(\Sigma_t) \geq \underset{x\in \cX}{ \min }\; p_t(x)  \cdot \lambda_{\min}(\Sigma)$.
	\item[(iii)] MGR estimate of (ii), for which it is known (\cite{BOBWlinear}[Lemma 2]) that $\norm{\Sigma_t^+}_{\text{op}} \leq \frac{(M_t+1)}{2}$.
\end{itemize}

The bound for the MGR estimates encourages to tune $M_t$ at most of order $\frac{1}{\eta_t}$, which is what is done in \cite{BOBWlinear}. This can in turn impose constraints on the tuning of $\eta_t$ (in that case the tuning of $u_t$ will appear in the control of the bias), which gives the extra logs in \cite{BOBWlinear}.  

Apart from the MGR estimate, it seems that the above bounds impose a strong constraint on $p_t$, and so on $u_t$. Indeed, as in \cite{BOBWhardproblems} we use $u_t$ to meet the condition above by choosing it to be $u_t(x)=\eta_t v_t(x)$ for some function $v$. Unfortunately, without proving more properties on $p_t$ it seems that $u_t$ must be uniformly bounded (in both case). In particular, it seems that one must impose 
\begin{equation}\label{eq::cond_ut}\forall x \in \cX, \; u_t(x) = \frac{4\eta_t}{1-\alpha} \cdot \max_{x\in \cX} q_{t\star}(x)^{1-\alpha} \;. 
\end{equation}

\db{This is a bit hard to sell from a computational perspective. Can we find less ugly? If we replace the prob by $1/2$ what do we lose? Do we still get BOBW but get uglier logs? Note that if the context space is somewhat continuous nothing prevent several arms to be optimal/close to optimal, so this would be constant anyway\dots}

\db{An alternative path, but maybe super hard would be to upper bound the ratio $\sup_{x,y} \frac{q_{t, \star}(x)}{q_{t,\star}(y)}$.}

\db{Alternative alternative path: we can use the MGR samples to estimate the map of observation probabilities over contexts. Maybe we can use some sort of smoothness arguments to show that this would be enough to get a good tuning for $u_t$?}


If we can guarantee that \eqref{eq::as_bound} holds, we can then use Lemma~\ref{lem::ub_ftrl_technical} to bound the stability term by 

\[\stab\leq \frac{4}{1-\alpha} \bE\left[\sum_{t=1}^T   \bE_t\left[ \sum_{i \neq \wt I_t} q_{t,i}(x)^{2-\alpha} \wt \ell_{t,i}(x)^2 + q_{t\star}(x)^{2-\alpha} \wt \ell_{t,\wt I_t}(x)^2 \right] \right]\;. \]

To fit in the framework of \cite{BOBWhardproblems} we need to upper bound this term by $\frac{z_t(x)}{\beta_t \gamma'_t(x)}=\sqrt{\frac{z_t(x)}{\beta_t}}$.

Consider first estimate (i). Following Eq.\;(8) from \cite{NeuO20} we can use that, for all $i \in [K]$,  
\begin{align*}
\bE_t\left[\wt \ell_{t,i}^2\right]&\leq\bE_t\left[\frac{\ind(a\in O_t)}{p_t(X_t)^2} x^\top\Sigma^{-1}X_tX_t^\top\Sigma^{-1}x\right] \\
& = \bE_t\left[\frac{\ind(a\in O_t)}{p_t(X_t)^2}\text{Tr}(\Sigma^{-1}x x^\top\Sigma^{-1}X_t X_t^\top)\right] \\
& \leq \frac{d}{p_t(X_t)} \;.
\end{align*}
\db{Not usable unless we use the same observation probability for everyone, and get a unique $p_t=\sqrt{\frac{\bE_{X\sim \cD}[z_t(X)]}{\beta_t}}$. Let us elaborate a bit.}
Let us introduce 
\[Z_t(x)\coloneqq   \sum_{i \neq \wt I_t} q_{t,i}(x)^{2-\alpha} + q_{t\star}(x)^{2-\alpha}\;. \]
Then, if we fix a shared $p(X_t)=\bar p_t$ for all $t$ and $X_t$, we can obtain that 
\[\bE_t[\stabt] \leq \beta_t^{-1} \underbrace{(cK \bar p_t)^{-1}}_{\gamma_t^{-1}} \cdot  \underbrace{\frac{4cKd}{1-\alpha}\cdot \bE_{X\sim \cD}[Z_t(X)]}_{z_t} , \] 
if we consider that the ghost sample is independent from the filtration (that is, the filtration is just about things that were seen by the alg). With this writing, the $z_t$ that we fit in the framework of \cite{BOBWhardproblems} is defined as an expectation over contexts, and the SPB matching can then proceed as they describe. \db{Which needs to be checked though, in particular the next step is to have a look at the entropy property for the penalty term.}

\db{All of this is Ok if we can evaluate it up to a good approximation.} \db{So in summary, with estimate (i) it seems that we can complete the bound on the stability term using the SPB matching definition, and defining $u_t$ as in Eq.~\eqref{eq::cond_ut}. Note that in the case where $p_t$ is uniform then estimates (i) and (ii) match and MGR is not necessary, or just before the interaction to get an approximation of $\Sigma^{-1}$ up to an arbitrary precision.}


Using $\Sigma_t$ as in (ii), we get 
\begin{align*}
	\bE_t\left[\wt \ell_{t,i}^2\right]&\leq\bE_t\left[\ind(a\in O_t) x^\top\Sigma_t^{-1}X_tX_t^\top\Sigma_t^{-1}x\right] \\ &  =
	 x^\top\Sigma_t^{-1}\cdot p_t(X_t)X_tX_t^\top\Sigma_t^{-1}x \;.
\end{align*}
We then write that 
\begin{align}
	\stab &\leq \frac{4}{\beta_t(1-\alpha)} \sum_{t=1}^T \bE\left[\frac{Z_t(x)}{p_t(x)} \text{Tr}(p_t(x)xx^\top \Sigma_t^{-1} X_t X_t^\top p_t(X_t)\Sigma_t^{-1})\right] \;.
\end{align}
Now to be able to do the same as for Lemma 6 of \cite{NeuO20} we would need to have $Z_t(x)/p_t(x)=1$, so the expectation could go in the trace and yield only a $d$ factor. \db{I don't know how to deal with this term, which looks rather necessary if we don't want to use a uniform probability.}  


\paragraph{Controlling the penalty term.} \db{Previous draft} \antoine{If I understand correctly the second regularizer becomes useful to enable the use of Lemma~\ref{lem::ftrl_smooth_bound}}
\db{The second regularizer controls the ratio of entropies in-between rounds, that is condition (iii) in Thm. 7 of \cite{BOBWhardproblems}.}

\db{Since the learning rate update is defined for SPB matching the only thing to do here is to control this entropy. Seems all arguments from \cite{BOBWhardproblems} should readily apply here with the ghost sample trick.}

\db{Tldr, this part should be trivial with context-dependent probs.}

\paragraph{Penalty term under $\bar p_t$ algorithm design}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PROOF OF LEMMA~\ref{lem::adapt_tsuchaya}} \label{Appendix}

\adath*

\begin{proof}[Proof of Lemma~\ref{lem::adapt_tsuchaya}]
The argument follows the same general structure of the proof of Theorem~7 in \cite{BOBWhardproblems}. 
We first define
    \begin{equation*}
\gamma'_t \coloneqq \gamma_t - \frac{u_t}{\beta_t} = \sqrt{\frac{z_t}{\beta_t}}.
    \end{equation*}


Starting from the regret decomposition given by Assumption~(i) of the lemma, we have:
\begin{align*}
R_T 
&\leq \bbE\Bigg[\sumtT \Big( 
\Big(\frac{1}{\eta_t} - \frac{1}{\eta_{t-1}}\Big) h_t 
+ \frac{z_t \eta_t}{\gamma_t}
+ \gamma_t \Big)  \Bigg] + \bar{\beta}\bar{h}
\\
&\text{\small (by Assumption (i) of the lemma)} \\[0.4em]
&= \bbE\Bigg[\sumtT \Big( 
(\beta_t - \beta_{t-1}) h_t 
+ \frac{z_t \eta_t}{\gamma_t} 
+ \gamma_t \Big) \Bigg]+ \bar{\beta}\bar{h}
\end{align*}

where we used $\beta_t = 1/\eta_t$ and $\bar{h} = \max_{p \in \Delta_K} H_{\bar{\alpha}}(p)$.
We now replace $\gamma_t$ by $\gamma'_t \le \gamma_t$ to simplify the analysis (this may loosen the bound slightly but keeps the algebra tractable):
\begin{align*}
R_T 
&\leq \bbE\Bigg[\sumtT \Big( 
(\beta_t - \beta_{t-1}) h_t 
+ \frac{z_t \eta_t}{\gamma'_t} 
+ \gamma_t \Big) \Bigg]+ \bar{\beta}\bar{h} \\[0.4em]
&= \sumtT \bbE\!\left[ 
(\beta_t - \beta_{t-1}) h_t 
+ \frac{z_t \eta_t}{\gamma'_t} 
+ \gamma_t \right]
+ \bar{\beta}\bar{h}
\end{align*}

\paragraph{Bounding the first term.}
We first upper bound $\sumtT \bbE[(\beta_t - \beta_{t-1}) h_t]$.  
By the tower rule and the fact that $(\beta_t - \beta_{t-1})$ is $\cH_{t-1}$-measurable, we have
\begin{align*}
\sumtT \bbE \!\left[ (\beta_t - \beta_{t-1}) h_t \right] 
&= \sumtT \bbE \!\left[ 
(\beta_t - \beta_{t-1}) \, 
\bbE[h_t \mid \cH_{t-1}] \right].
\end{align*}
Then, by Assumption~(ii), which ensures 
$\bbE[h_t \mid \cH_{t-1}] \le 2 \, \bbE[h_{t-1} \mid \cH_{t-2}]$, we get:
\begin{align*}
\sumtT \bbE \!\left[ (\beta_t - \beta_{t-1}) h_t \right]
&\le 2 \sumtT \bbE\!\left[ (\beta_t - \beta_{t-1}) h_{t-1} \right].
\end{align*}

\paragraph{Bounding the remaining terms.}
Using the definitions of $\gamma_t$ and $\gamma_t'$, namely
$\gamma'_t = \sqrt{z_t / \beta_t}$ and $\gamma_t = \gamma'_t + u_t / \beta_t$, we have
\begin{align}\label{eq::critical step}
\sumtT \bbE\!\left[\frac{z_t \eta_t}{\gamma'_t} + \gamma_t \right]
&= \sumtT \bbE\!\left[
\sqrt{\frac{z_t}{\beta_t}} + 
\Big( \sqrt{\frac{z_t}{\beta_t}} + \frac{u_t}{\beta_t} \Big) \right] \\
&\le \sumtT \bbE\!\left[
2\sqrt{\frac{z_t}{\beta_t}} + \frac{u_t}{\beta_t} \right]. \nonumber
\end{align}

Combining the two results above, we obtain:
    \begin{equation*}
R_T \le 
\bbE\!\left[
F(\beta_{1:T}, z_{1:T}, u_{1:T}, h_{0:T-1})
\right]
+ \bbE[\bar{\beta}\bar{h}],
    \end{equation*}
where we define
    \begin{equation*}
F(\beta_{1:T}, z_{1:T}, u_{1:T}, h_{1:T})
\coloneqq \sumtT 
\left(
(\beta_t - \beta_{t-1}) h_t
+ 2\sqrt{\frac{z_t}{\beta_t}}
+ \frac{u_t}{\beta_t}
\right).
    \end{equation*}
Note that the regret upper bound we obtained at this step involves the sequence $h_{0:T-1}$, and not $h_{1:T}$ as in the above definition.  


\paragraph{Adversarial regime}
Using Lemma~\ref{hardthm6},
we obtain that, for any $\epsilon \ge 1/T$,
\begin{align*}
F(\beta_{1:T}, z_{1:T}, u_{1:T}, h_{0:T-1})
&\le \left( 
\left[ \sumtT \sqrt{z_t h_t} \right] 
\log(\epsilon T)
\right)^{2/3} \\
&\quad + \sqrt{
\left[ \sumtT u_t h_t \right]
\log(\epsilon T)
} \\
&\quad + 
\left( \frac{\sqrt{z_{\max} h_1}}{\epsilon} \right)^{2/3}
+ \sqrt{ \frac{u_{\max} h_1}{\epsilon} }
+ \kappa.
\end{align*}

Substituting this into the previous inequality gives the claimed regret bound for the adversarial case:
\begin{align*}
R_T \le &
\left( 
\bbE\left[\sumtT \sqrt{z_t h_t}\right]
\log(\epsilon T)
\right)^{2/3} 
+ 
\sqrt{
\bbE\left[\sumtT u_t h_t\right]
\log(\epsilon T)
} \\
& + 
\left( \frac{\sqrt{z_{\max} h_1}}{\epsilon} \right)^{2/3}
+ 
\sqrt{ \frac{u_{\max} h_1}{\epsilon} }
+ \kappa.
\end{align*}
Setting $\epsilon = 1/T$ yields the desired bound in the adversarial regime.

\paragraph{Stochastic regime.}
We now turn to the stochastic case, under Assumptions~(iii)–(iv). 
Define
    \begin{equation*}
\varrho_0(\pi^\star_T) 
\coloneqq \sumtT 
\left( 1 - q_t(\pi^\star_T(X_t) \mid X_t) \right).
    \end{equation*}
%\red{$\pi^\star$ should be replaced by $\pi^\star_T$ below}
By Assumptions~(iii)–(iv),
\begin{align*}
\bbE\!\left[\sumtT \sqrt{z_t h_t}\right]
&\le \sqrt{\rho} \cdot \varrho_0(\pi_T^\star), \\
\bbE\!\left[\sumtT u_t h_t\right]
&\le \rho \cdot \varrho_0(\pi_T^\star).
\end{align*}
Furthermore, Lemma~21 of \cite{BOBWlinear} gives the lower bound
    \begin{equation*}
R_T \ge \frac{\deltamin}{2} \, \bbE[\varrho_0(\pi^\star)] - 2C.
    \end{equation*}

Balancing both bounds using any $\lambda \in (0,1]$, and applying the inequalities 
$a x^2 - b x^3 \le \tfrac{4 a^3}{27 b^2}$ 
and 
$a x - b x^2 \le \tfrac{a^2}{4b}$ 
(for $a \ge 0$, $b > 0$), 
we obtain after simplification:
\begin{align*}
R_T \lesssim
&\frac{(1+\lambda)^3}{\lambda^2} 
\cdot \frac{\rho \log(\epsilon T)}{\deltamin^2}
+ \frac{(1+\lambda)^2}{\lambda} 
\cdot \frac{\rho \log(\epsilon T)}{\deltamin} \\
&\quad + 
\left( \frac{\sqrt{z_{\max} h_1}}{\epsilon} \right)^{2/3}
+ \sqrt{ \frac{u_{\max} h_1}{\epsilon} }
+ \kappa + 2\lambda C.
\end{align*}

Choosing $\lambda = \Theta\!\left( 
\left( \tfrac{\rho \log(\epsilon T)}{C} \right)^{1/3}
\right)$ 
and setting $\epsilon = 1 / (\rho^2/\deltamin^3 + C\rho/\deltamin) \le 1/T$
gives, for $T \ge \tau \coloneqq \tfrac{1}{\deltamin^3} + \tfrac{C}{\deltamin}$,
\begin{align*}
R_T \lesssim
&\frac{\rho}{\deltamin^2} 
\log_+\!\left( T\deltamin^3 \right)
+ 
\left(
\frac{C^2 \rho}{\deltamin^2}
\log_+\!\left( \frac{T\deltamin}{C} \right)
\right)^{1/3} \\
&+ 
\left( (z_{\max} h_1)^{1/3}
+ \sqrt{u_{\max} h_1} \right)
\left( \frac{1}{\deltamin^3} + \frac{C}{\deltamin} \right)^{2/3}
+ \kappa,
\end{align*}
which concludes the proof.
\end{proof}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PROOF OF THEOREM~\ref{thm::main}}\label{AppendixRegret}


We build on Lemma~\ref{lem::adapt_tsuchaya}, presented and proved in Appendix~\ref{Appendix}, to prove Theorem~\ref{thm::main} by verifying that Algorithm~\ref{alg::FTRL_bobw} satisfies conditions~(i)–(iv) of the lemma. We recall the theorem below, before presenting its proof. 

\MainTheorem*


\begin{proof} \DB{Tldr: all this part is shit because it mixes using fixed context and current context, with ambiguous notation that doesn't allow to understand in which case we are.}
We verify that Algorithm~\ref{alg::FTRL_bobw} satisfies the four conditions of Lemma~\ref{lem::adapt_tsuchaya}.



Throughout this proof, we work with the \emph{exact} loss estimates $\wh{\theta}_{t, a}$ defined in Eq.~\eqref{eq::estimator}, rather than their MGR approximations $\wt{\theta}_{t, a}$ used in the algorithmic description. 
This distinction is only technical and does not affect the regret order, since Lemma~\ref{lem::boundBias} guarantees that the cumulative bias introduced by the MGR approximation remains uniformly bounded.

\noindent\textbf{Condition (i).} 
By definition of the importance-sampled loss (Eq.~\eqref{eq::estimator}), 
for any $a \in \sbr*{K}$ we have
    \begin{equation*}
|\wh{\ell}_{t, a} \eta_t|
\le \frac{\ell_{t, a}\eta_t}{p_t \lambda_{\min}}
\le \frac{1}{u_t \lambda_{\min}}
\le \frac{1 - \alpha}{8} 
\cdot \frac{1}{\min(q_{t,a_t^\star}, 1 - q_{t,a_t^\star})^{1 - \alpha}}.
    \end{equation*}
Hence, the scaled losses $\wh{\ell}_t \eta_t$ satisfy the condition of Lemma~\ref{lem::ub_ftrl_technical}, presented in Appendix~\ref{Appendix}, which provides an upper bound on the penalty term 
\(\langle q_t - q_{t+1}, \wh{\ell}_t \spr*{x}\rangle - D_t(q_{t+1},q_t)\) 
appearing in the standard FTRL regret decomposition.

\DB{Imo, has to be re-written from the start with the ghost sample $x$ and with the estimates $\wt \theta_{t, a}$ actually used by FTRL.}
Since the regret is defined by 
    \begin{equation*}
R_T = 
\bbE\!\left[ 
\sumtT 
\left( 
\langle X_t, \theta_{t,A_t} \rangle 
- \langle X_t, \theta_{t,\pi^\star(X_t)} \rangle 
\right) 
+ cK \sumtT p_t
\right],
    \end{equation*}
and $\wh{\theta}_{t, a}$ is an unbiased estimator of $\theta_{t, a}$, we can equivalently write
    \begin{equation*}
R_T =
\bbE\!\left[
\sumtT 
\left(
\langle X_t, \wh{\theta}_{t,A_t} \rangle 
- \langle X_t, \wh{\theta}_{t,\pi^\star(X_t)} \rangle 
\right)
+ cK \sumtT p_t
\right].
    \end{equation*}
\DB{This is wrong without using the ghost sample technique, cause the estimates depend on $X_t$ (with some $X_0$, it's OK).}

Fix any context $x \in \bbR^d$.  
Applying Lemma~\ref{lem::standard_regret_decompo}, we obtain:
\begin{align*}
\sumtT 
\left( 
\langle x, \wh{\theta}_{t,A_t} \rangle 
- \langle x, \wh{\theta}_{t,\pi^\star \spr*{x}} \rangle 
\right)
\le
&\quad\underbrace{
\sumtT \big( \psi_t(q_{t+1}(.|x)) - \psi_{t+1}(q_{t+1}(.|x)) \big)
}_{\text{penalty}} \\[0.3em]
&+ 
\underbrace{
\sumtT \big( 
\langle q_t(.|x) - q_{t+1}(.|x), \wh{\ell}_t \spr*{x} \rangle 
- D_t(q_{t+1}(.|x), q_t(.|x))
\big)
}_{\text{stability}} 
+ A + \bar{\beta}\bar{h},
\end{align*}
where $A = \psi_{T+1}(\pi^\star(\cdot|x)) - \psi_1(q_1(\cdot|x)) \le \beta_1 \log K$ is independent of $T$ and will be ignored in the sequel (together with $\bar{\beta}\bar{h}$).

\paragraph{Bounding the penalty term.}
By the definition of $\psi_t$, we have
    \begin{equation*}
\sumtT 
\big( \psi_t(q_{t+1}(.|x)) - \psi_{t+1}(q_{t+1}(.|x)) \big)
\le 
\sumtT 
\Big( \frac{1}{\eta_{t+1}} - \frac{1}{\eta_t} \Big) h_{t+1}.
    \end{equation*}
\DB{Now here this is were messing up with the notation is confusing: above check which components should depend on $x$.}
Reindexing $t \mapsto t-1$ yields the equivalent form
    \begin{equation*}
\sumtT 
\Big( \frac{1}{\eta_t} - \frac{1}{\eta_{t-1}} \Big) h_t.
    \end{equation*}

\paragraph{Bounding the stability term.}
Using Lemma~\ref{lem::ub_ftrl_technical} together with Lemma~\ref{lem::bound_squared_loss}, we have
\begin{align}
\sumtT 
\big(
\langle q_t - q_{t+1}, \wh{\ell}_t \spr*{x} \rangle 
- D_t(q_{t+1}, q_t)
\big) 
&= 
\sumtT 
\frac{1}{\eta_t}
\left(
\langle q_t - q_{t+1}, \wh{\ell}_t \spr*{x}\eta_t \rangle
- D_t(q_{t+1}, q_t)
\right) \nonumber\\
&\le
\sumtT 
\frac{4 \eta_t}{1 - \alpha}
\left(
q_{t,a_t^\star}^{2 - \alpha} \wh{\ell}_{t, a_t^\star}^2
+ \sum_{a \neq a_t^\star} q_{t, a}^{2 - \alpha} \wh{\ell}_{t, a}^2
\right) \label{eq::bad_conditioning} \\
&\le
\sumtT 
\frac{4 d^2 \eta_t}{p_t (1 - \alpha) \lambda_{\min}^2}
\left(
q_{t,a_t^\star}^{2 - \alpha}
+ \sum_{a \neq a_t^\star} q_{t, a}^{2 - \alpha}
\right). \nonumber
\end{align}
\DB{Isn't there some $\min(q,1-q)$ at some point in lemma 3? Otherwise why split between $a_t^\star$ and $a\neq a_t^\star$. Not consistent}

\DB{More important: lemma 2 bounds $\bE[\widehat l_{t, a}^2]$ while here you should have a bound on $\bE[q_{t, a}^{2-\alpha} \cdot \widehat\ell_{t, a}^2]$. Transposing previous works we would work on $\bE[\sum_{a=1}^K q_{t, a}^{2-\alpha} \cdot \widehat\ell_{t, a}^2]$ directly.}

Taking expectations over the random context $X_t$, we obtain
\begin{align*}
\bbE[R_T]
&\le 
\bbE\Bigg[
\sumtT 
\Big( \frac{1}{\eta_t} - \frac{1}{\eta_{t-1}} \Big) h_t \\
&\quad +
\sumtT 
\frac{4 d^2 \eta_t}{p_t (1 - \alpha) \lambda_{\min}^2}
\Big(
q_{t,a_t^\star}^{2 - \alpha}
+ \sum_{a \neq a_t^\star} q_{t, a}^{2 - \alpha}
\Big)
+ cK \sumtT p_t
\Bigg],
\end{align*}
which matches the required structure of condition~(i).

\DB{It seems we should not be doing that but instead use a ghost sample to define the regret as in \cite{BOBWhardproblems, BOBWlinear}.}

\paragraph{Condition (ii).}
Condition~(ii) follows directly from Lemma~\ref{lem::cond_bound_ht}, presented and proved in Appendix~\ref{Appendix}, which guarantees that
    \begin{equation*}
\bbE[h_{t+1} \mid \cH_t]
\le 
2 \, \bbE[h_t \mid \cH_{t-1}],
\qquad \forall t \ge 1.
    \end{equation*}

\paragraph{Conditions (iii) and (iv).}
Lemma~13 of \cite{BOBWhardproblems} provides an upper bound on the entropy term,
    \begin{equation*}
h_t \le \frac{1}{\alpha}(K-1)^{1-\alpha} (1 - q_{t,a_t^\star})^{\alpha},
    \end{equation*}
where $a_t^\star \coloneqq \text{arg max}_{a \in \sbr*{K}} \langle X_t, \theta_{t, a} \rangle$ denotes the optimal arm for context $X_t$.
Moreover, using the definitions of $z_t$ and $u_t$, we obtain:
\begin{align*}
z_t
&= \frac{4 c K d^2}{(1 - \alpha) \lambda_{\min}^2}
\left(
\sum_{a \neq a_t^\star} q_{t, a}^{2 - \alpha}
+ (\min(q_{t,a_t^\star}, 1 - q_{t,a_t^\star}))^{2 - \alpha}
\right) \\
&\le 
\frac{8 c K d^2}{(1 - \alpha) \lambda_{\min}^2}
(1 - q_{t,a_t^\star})^{2 - \alpha}.
\end{align*}
Combining the bounds on $h_t$ and $z_t$ yields
\begin{align*}
z_t h_t 
&\le 
\frac{8 c K d^2 (K-1)^{1-\alpha}}{\alpha\spr*{1 - \alpha}\lambda_{\min}^2}
(1 - q_{t,a_t^\star})^2,\\
u_t h_t 
&\le 
\frac{8 d \max(c,1)}{\spr*{1 - \alpha}\alpha}(K-1)^{1-\alpha}
(1 - q_{t,a_t^\star}).
\end{align*}
Hence, both conditions are satisfied with
\begin{align*}
\sqrt{z_t h_t} &\le \sqrt{\rho}\,(1 - q_{t,a_t^\star}),\\
u_t h_t &\le \rho\,(1 - q_{t,a_t^\star}),
\end{align*}
where
    \begin{equation*}
\rho \coloneqq 
\frac{d}{\lambda_{\min}}
\max\!\left(
\sqrt{\frac{8cK(K-1)^{1-\alpha}}{\alpha\spr*{1 - \alpha}}},
\frac{8 \max(c,1)}{\spr*{1 - \alpha}\alpha}(K-1)^{1-\alpha}
\right).
    \end{equation*}

\paragraph{Conclusion.}
Having verified conditions~(i)–(iv), we can invoke Lemma~\ref{lem::adapt_tsuchaya} to conclude that Algorithm~\ref{alg::FTRL_bobw} enjoys a Best-of-Both-Worlds (BoBW) regret guarantee.  
To make the constants explicit, note that
    \begin{equation*}
h_{\max} \le \frac{K^{1-\alpha}}{\alpha}, \qquad
z_{\max} = \mathcal{O}\!\left(\frac{cK d^2}{(1 - \alpha)\lambda_{\min}^2}\right), \qquad
u_{\max} = \mathcal{O}\!\left(\frac{d \max(c,1)}{1 - \alpha}\right).
    \end{equation*}
Plugging these into Lemma~\ref{lem::adapt_tsuchaya} gives
\begin{align*}
\text{Adversarial regime: } &
R_T = \mathcal{O}\!\left(
\left( \frac{cK d^2}{\lambda_{\min}^2} \right)^{1/3} T^{2/3}
+ \sqrt{ \frac{d \max(c,1) T}{\lambda_{\min}} }
\right),\\
\text{Corrupted stochastic regime: } &
R_T = \mathcal{O}\!\left(
\frac{d \sqrt{\max(c,1)K}}{\lambda_{\min}\deltamin^2}\log(T\deltamin^3)
+ \left(
\frac{C^2 d \sqrt{\max(c,1)K}}{\lambda_{\min}\deltamin^2}
\log\!\frac{T\deltamin}{C}
\right)^{1/3}
\right).
\end{align*}

This completes the proof of Theorem~\ref{thm::main}.
\end{proof}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
